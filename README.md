# ğŸ¤– AI Requirements Engineer

A modern desktop application that uses **Local LLMs (Large Language Models)** to automatically analyze software requirements documents. It reads PDF or Word files, extracts functional and non-functional requirements, and exports a professional reportâ€”**100% locally and offline** for maximum data privacy.

---

## âœ¨ Features

* **ğŸ“„ Multi-Format Support:** Reads `.pdf` and `.docx` (Word) files.
* **ğŸ§  Local AI Intelligence:** Uses the **Qwen 2.5 (3B)** model via Ollama to analyze text without sending data to the cloud.
* **ğŸ§¹ Smart Preprocessing:** Automatically cleans artifacts, page numbers, and formatting issues from raw text.
* **ğŸ“Š Structured Output:** Classifies requirements into:
* Functional Requirements
* Non-Functional Requirements
* Risks & Open Questions


* **ğŸ’¾ Auto-Export:** Automatically saves the analysis as formatted **PDF** and **Word** reports.
* **ğŸ¨ Modern UI:** Built with `CustomTkinter` for a clean, dark-mode interface.

---

## ğŸ› ï¸ Prerequisites

Before running the application, you need to set up the AI Engine.

### 1. Install Ollama (The AI Engine)

This application relies on **Ollama** to run the AI model locally.

1. Download Ollama from [ollama.com](https://ollama.com/download).
2. Install it on your system.
3. Ensure it is running (you should see a llama icon in your taskbar).

### 2. Download the Model

Open your terminal (Command Prompt / PowerShell) and run the following command to download the specific model used by this tool:

```bash
ollama pull qwen2.5:3b

```

*(Note: This download is approx. 1.9 GB. You can change the model in `core/analyzer.py` if you prefer Llama 3 or others.)*

---

## ğŸš€ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/Diyarino/requirements-engineering.git
cd requirements-engineering

```

### 2. Set up Python Environment (Recommended)

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Mac/Linux)
source venv/bin/activate

```

### 3. Install Dependencies

```bash
pip install -r requirements.txt

```

---

## ğŸ’» Usage

### Running from Source

Simply execute the main script:

```bash
python main.py

```

1. Click **"1. Datei wÃ¤hlen"** to select your requirements document (PDF/DOCX).
2. Click **"2. Analyse starten"**.
3. Wait for the AI to process the text (Progress bar will indicate activity).
4. A result window will open, and the reports (`.pdf` and `.docx`) will be saved in the same folder as your input file.

<p align="center">
  <img src="img/screen0.png" width="30%" />
  <img src="img/screen1.png" width="30%" />
  <img src="img/screen2.png" width="30%" />
</p>

### Building an Executable (.exe)

If you want to create a standalone application to share with colleagues:

```bash
python build_exe.py

```

The finished `.exe` will appear in the `dist/` folder.

---

## ğŸ“‚ Project Structure

```text
AI-Requirements-Engineer/
â”œâ”€â”€ core/                   # Backend Logic
â”‚   â”œâ”€â”€ analyzer.py         # AI Interaction (Ollama)
â”‚   â”œâ”€â”€ exporter.py         # PDF/Docx Generation
â”‚   â””â”€â”€ file_handler.py     # File Reading & Preprocessing
â”œâ”€â”€ ui/                     # User Interface
â”‚   â”œâ”€â”€ main_window.py      # Main GUI (CustomTkinter)
â”‚   â””â”€â”€ result_window.py    # Popup for Results
â”œâ”€â”€ main.py                 # Entry Point
â”œâ”€â”€ config.py               # Settings
â”œâ”€â”€ setup_model.bat         # Helper script for model setup
â””â”€â”€ requirements.txt        # Python Dependencies

```

---

## ğŸ›¡ï¸ Privacy & Security

This tool was designed with data security in mind. Unlike ChatGPT or cloud-based tools, **no data leaves your computer**. The document analysis happens entirely within your local Ollama instance. This makes it suitable for confidential business documents (NDAs).

---

## ğŸ“ License

This project is open source. Feel free to modify and distribute.

---

